{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count Vectorizer / Algorithm\n",
    "\n",
    "In the context of machine learning and `natural` language processing, Count Vectorizer\" refers  \n",
    "to the overall method of `converting` a collection of text documents into a matrix of token counts.  \n",
    "This process typically `involves` both the \"fit\" and \"transform\" steps.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Vocabulary / Step 1\n",
    "\n",
    "Learn the `vocabulary` (unique words) from the provided text data.   \n",
    "We create a list (set) of all `unique` tokens across all documents.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'London', 'Paris'}\n"
     ]
    }
   ],
   "source": [
    "# Sample text strings\n",
    "a = 'London Paris London'\n",
    "b = 'Paris Paris London'\n",
    "\n",
    "def create_vocabulary(texts):\n",
    "    vocabulary = set()\n",
    "\n",
    "    for t in texts:\n",
    "        # Split each document into tokens (usually words)\n",
    "        words = t.split()\n",
    "\n",
    "        # Create a list of all unique tokens across all documents\n",
    "        for w in words:\n",
    "            vocabulary.add(w)\n",
    "    return vocabulary\n",
    "\n",
    "vocabulary = create_vocabulary([a, b])\n",
    "print(vocabulary)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count Matrix / Step 2\n",
    "\n",
    "Convert the text documents into a `numerical` format (specifically, a token count matrix)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2], [2, 1]]\n"
     ]
    }
   ],
   "source": [
    "def fit_transform(texts):\n",
    "    # Create a set of unique words (vocabulary)\n",
    "    vocabulary = create_vocabulary(texts)\n",
    "\n",
    "    # Convert the set to a list for indexing\n",
    "    vocabulary = list(vocabulary)\n",
    "\n",
    "    # Initialize an empty list to store the count vectors\n",
    "    matrix = []\n",
    "\n",
    "    # Iterate through each text in the input\n",
    "    for t in texts:\n",
    "        # Create a count vector initialized with zeros for each word\n",
    "        count_vector = [0] * len(vocabulary)\n",
    "\n",
    "        # Iterate through each word in the current text\n",
    "        for word in t.split():\n",
    "            # Find the index of the word in the vocabulary\n",
    "            index = vocabulary.index(word)\n",
    "            \n",
    "            # Increment the count for this word in the count vector\n",
    "            count_vector[index] += 1\n",
    "\n",
    "        matrix.append(count_vector)\n",
    "    return matrix\n",
    "\n",
    "# Sample text strings\n",
    "a = 'London Paris London'\n",
    "b = 'Paris Paris London'\n",
    "\n",
    "# Get the frequency matrix\n",
    "matrix = fit_transform([a, b])\n",
    "print(matrix)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scikit\n",
    "\n",
    "Both processes (fit, transform) are `encapsulated` in the fit_transform method in scikit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t2\n",
      "  (0, 1)\t1\n",
      "  (1, 0)\t1\n",
      "  (1, 1)\t2\n",
      "[[1.  0.8]\n",
      " [0.8 1. ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "a = 'London Paris London'\n",
    "b = 'Paris Paris London'\n",
    "\n",
    "cv = CountVectorizer()\n",
    "\n",
    "matrix = cv.fit_transform([a, b])\n",
    "print(matrix)\n",
    "\n",
    "similarity_scores = cosine_similarity(matrix)\n",
    "print(similarity_scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
