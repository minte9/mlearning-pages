{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proability\n",
    "\n",
    "Probability is the `chance` of something to happen.  \n",
    "When you flip a `coin`, there is a probability of 0.5 (or 50% chance) to land on heads.  \n",
    "\n",
    "It's `like` asking, \"What are the chances of something to happen?\"  \n",
    "Probability is a number `between` 0 and 1, where 0 means \"no way\" and 1 means \"definitely happening\".  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Head = 0.5\n",
      "Tail = 0.5\n"
     ]
    }
   ],
   "source": [
    "# Coin Flip events\n",
    "events = ['head', 'tail']\n",
    "\n",
    "# Output probabilies\n",
    "print('Head =', 1/2)\n",
    "print('Tail =', 1/len(events))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proability Distribution\n",
    "\n",
    "Now, imagine you're not just flipping a coin but `rolling` a dice.  \n",
    "There are more `outcomes` (1 through 6), each with its own probability.  \n",
    "\n",
    "A probability distribution is a `list` with all these probabilities.  \n",
    "It's like a `map` with all the possible outcomes and how likely they are.\n",
    "\n",
    "A probability gives you the `chance` for an event.  \n",
    "A probability distribution tells the `story` for all posible outcomes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| A: ['apple', 'orange', 'orange', 'banana', 'banana']\n",
      "ic| B: ['apple', 'apple', 'apple', 'apple', 'apple', 'orange', 'orange']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| PA_hand: [{'apple': 0.2}, {'orange': 0.4}, {'banana': 0.4}]\n",
      "ic| PB_hand: [{'apple': 0.7142857142857143}, {'orange': 0.2857142857142857}]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from icecream import ic\n",
    "\n",
    "# Dataset\n",
    "A = ['apple']*1 + ['orange']*2 + ['banana']*2\n",
    "B = ['apple']*5 + ['orange']*2 + ['banana']*0\n",
    "\n",
    "ic(A)\n",
    "ic(B)\n",
    "\n",
    "# Probability (by HAND)\n",
    "PA_hand = [{'apple': 1/5}, {'orange': 2/5}, {'banana': 2/5}] \n",
    "PB_hand = [{'apple': 5/7}, {'orange': 2/7}]\n",
    "\n",
    "display('\\n')\n",
    "\n",
    "ic(PA_hand)\n",
    "ic(PB_hand)\n",
    "\n",
    "# Probability (with PANDAS)\n",
    "PA_pandas = pd.Series(A).value_counts(normalize=True)\n",
    "PB_pandas = pd.Series(B).value_counts(normalize=True)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entropy\n",
    "\n",
    "Entropy is a measure of how `disordered` a collection is.  \n",
    "The more `impure` the feature is, the higher the entropy.  \n",
    "\n",
    "Probability distribution is the `frequency` of the unique values.  \n",
    "It turns out that a `logarithm` of the number of states is perfect for compute entropy.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from icecream import ic\n",
    "\n",
    "# Set the initial traning data\n",
    "A = ['apple']*1 + ['orange']*2 + ['banana']*2\n",
    "B = ['apple']*5 + ['orange']*2 + ['banana']*0\n",
    "\n",
    "# Probability\n",
    "PA_pandas = pd.Series(A).value_counts(normalize=True)\n",
    "PB_pandas = pd.Series(B).value_counts(normalize=True)\n",
    "ic(PA_pandas)\n",
    "ic(PB_pandas)\n",
    "\n",
    "# Entropy (Shannon model)\n",
    "P1 = PA_pandas.values\n",
    "P2 = PB_pandas.values\n",
    "H1 = -1 * np.sum(P1 * np.log2(P1))\n",
    "H2 = -1 * np.sum(P2 * np.log2(P2))\n",
    "\n",
    "\n",
    "ic(H1)\n",
    "ic(H2)\n",
    "\n",
    "print(\"A entropy > B entropy / There is more disorder in A than B\")\n",
    "print(\"Assertion passed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
